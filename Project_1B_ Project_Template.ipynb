{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# importing Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# getting current folder and subfolder event data\n",
    "filepath = os.getcwd() + \n",
    "\n",
    "# creating a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# joining the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 1008\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list,\n",
    "for f in file_path_list:\n",
    "    # read csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "         # extracting each data row one by one and append it\n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "print(\"Total number of rows:\", len(full_data_rows_list))\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 855\n"
     ]
    }
   ],
   "source": [
    "# checking the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(\"Number of rows:\", sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## The <font color=red>event_datafile_new.csv</font> file, located within the Workspace directory, contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is an example of what the denormalized data will appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance in the local machine (127.0.0.1)\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, we need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS sparkify WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 1}\")\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Setting Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### To run the following queries, we will need to create distinct tables, because with Apache Cassandra you must model the database tables on the queries you wants to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Goal Queries:\n",
    "\n",
    "### 1. List of artists, song titles and songs' length in the music app history that were heard during sessionId = 338 and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10 and sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. User names (first and last) in the music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Creating tables and running queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 1. Retrieve the artist, song title and song's length in the music app history that was heard during sessionId = 338 and itemInSession  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS songs_by_sessions\"\n",
    "query = query + \"(session_id int, item_session int, artist text, song_title text, song_length double, \\\n",
    "                    PRIMARY KEY (session_id, item_session))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO songs_by_sessions (session_id, item_session, artist, song_title, song_length)\"\n",
    "        query = query +  \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT artist, song_title, song_length FROM songs_by_sessions WHERE session_id = 338 AND item_session = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.artist, \"-\", row.song_title, \",\", row.song_length, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 2: Retrieve the artists' names, the songs (sorted by itemInSession) and user name (first and last name) for userid = 10 and sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query2 = \"CREATE TABLE IF NOT EXISTS songs_by_users_and_sessions\"\n",
    "query2 = query2 + \"(user_id int, session_id int, item_session int, artist text, song_title text, user_firstname text, user_lastname text, \\\n",
    "                    PRIMARY KEY ((user_id, session_id), item_session))\"\n",
    "try:\n",
    "    session.execute(query2)\n",
    "except Exception as e:\n",
    "    print(e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO songs_by_users_and_sessions (user_id, session_id, item_session, artist, song_title, user_firstname, user_lastname)\"\n",
    "        query = query +  \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone - Keep On Keepin' On ( Sylvie Cruz )\n",
      "Three Drives - Greece 2000 ( Sylvie Cruz )\n",
      "Sebastien Tellier - Kilometer ( Sylvie Cruz )\n",
      "Lonnie Gordon - Catch You Baby (Steve Pitron & Max Sanna Radio Edit) ( Sylvie Cruz )\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song_title, user_firstname, user_lastname FROM songs_by_user_and_session WHERE user_id = 10 AND session_id = 182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.artist, \"-\", row.song_title, \"(\", row.user_firstname, row.user_lastname, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 3: Retrieve user names (first and last) in the music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query3 = \"CREATE TABLE IF NOT EXISTS users_by_song_titles \"\n",
    "query3 = query3 + \"(song_title text, user_id int, user_firstname text, user_lastname text, \\\n",
    "                    PRIMARY KEY ((song_title), user_id))\"\n",
    "try:\n",
    "    session.execute(query3)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# it is important to note that the order of columns in the INSERT statement must follow the primary key order\n",
    "# for the same reason aforementioned in CREATE statement.\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO users_by_song_titles (song_title, user_id, user_firstname, user_lastname)\"\n",
    "        query = query +  \"VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT user_firstname, user_lastname FROM users_by_song_titles WHERE song_title = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "for row in rows:\n",
    "    print (row.user_firstname, row.user_lastname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Dropping the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "drop1 = \"DROP TABLE IF EXISTS songs_by_sessions\"\n",
    "drop2 = \"DROP TABLE IF EXISTS songs_by_users_and_sessions\"\n",
    "drop3 = \"DROP TABLE IF EXISTS users_by_song_titles\"\n",
    "try:\n",
    "    rows = session.execute(drop1)\n",
    "    rows = session.execute(drop1)\n",
    "    rows = session.execute(drop1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Closing the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Footnote: it is important to note that the order of columns in the CREATE statement must follow the primary key order, which means that the first columns in the CREATE clause consist of the partition key followed by all of the clustering columns in order. Only after that can we state other column names. This is required because Apache Cassandra determines which rows go to which nodes with the primary key for better efficiency when reading and writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
